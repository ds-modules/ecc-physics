{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df849023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 09-20-2006/fluctuation-rawdata.zip...\n",
      "Found 2030 EDC files\n",
      "Target: 15,000,000 samples (~5 minutes)\n",
      "  50 files, 2,500,000 samples\n",
      "  100 files, 5,000,000 samples\n",
      "  150 files, 7,500,000 samples\n",
      "  200 files, 10,000,000 samples\n",
      "  250 files, 12,500,000 samples\n",
      "  300 files, 15,000,000 samples\n",
      "  Loaded 301 files, stopped at 15,000,000 samples\n",
      "\n",
      "EDC Dataset:\n",
      "  Samples: 15,000,000\n",
      "  Duration: 5.00 minutes\n",
      "  Memory: 229 MB\n",
      "\n",
      "  Isd: mean=0.070311, std=0.027307\n",
      "  Range: [0.031258, 0.124999]\n",
      "\n",
      "Saved to 'edc_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def load_edc_first_5min(zip_path):\n",
    "    \"\"\"Load first 5 minutes of EDC data (18:26-18:31) using offset +3\"\"\"\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "        \n",
    "        temp_path = Path(temp_dir)\n",
    "        all_files = sorted(temp_path.rglob(\"*.dat\"))\n",
    "        real_files = [f for f in all_files if not f.name.startswith('._')]\n",
    "        \n",
    "        # Filter for EDC period (18:26-18:59)\n",
    "        edc_files = []\n",
    "        for f in real_files:\n",
    "            parts = f.stem.split('.')\n",
    "            if len(parts) >= 4:\n",
    "                try:\n",
    "                    hour, minute = int(parts[2]), int(parts[3])\n",
    "                    if hour == 18 and 26 <= minute <= 59:\n",
    "                        edc_files.append(f)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Found {len(edc_files)} EDC files\")\n",
    "        \n",
    "        # Target: 5 minutes\n",
    "        target_samples = 5 * 60 * 50000\n",
    "        print(f\"Target: {target_samples:,} samples (~5 minutes)\")\n",
    "        \n",
    "        data_chunks = []\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, filepath in enumerate(edc_files):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                raw = f.read()\n",
    "            \n",
    "            marker_pos = raw.find(b\"Isd\\tVsd\")\n",
    "            offset = marker_pos + len(b\"Isd\\tVsd\") + 3  # KEY: +3 offset!\n",
    "            trim_len = len(raw) - offset\n",
    "            trimmed = raw[offset:offset + (trim_len - (trim_len % 8))]\n",
    "            chunk = np.frombuffer(trimmed, dtype='<f4').reshape(-1, 2)\n",
    "            \n",
    "            if total_samples + len(chunk) > target_samples:\n",
    "                remaining = target_samples - total_samples\n",
    "                data_chunks.append(chunk[:remaining])\n",
    "                total_samples += remaining\n",
    "                print(f\"  Loaded {i+1} files, stopped at {total_samples:,} samples\")\n",
    "                break\n",
    "            else:\n",
    "                data_chunks.append(chunk)\n",
    "                total_samples += len(chunk)\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"  {i+1} files, {total_samples:,} samples\")\n",
    "        \n",
    "        combined = np.vstack(data_chunks)\n",
    "        \n",
    "        edc_df = pd.DataFrame({\n",
    "            'time_s': np.arange(len(combined)) * 0.00002,\n",
    "            'Isd': combined[:, 0],\n",
    "            'Vsd': combined[:, 1]\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nEDC Dataset:\")\n",
    "        print(f\"  Samples: {len(edc_df):,}\")\n",
    "        print(f\"  Duration: {edc_df['time_s'].iloc[-1]/60:.2f} minutes\")\n",
    "        print(f\"  Memory: {edc_df.memory_usage(deep=True).sum()/1024**2:.0f} MB\")\n",
    "        print(f\"\\n  Isd: mean={edc_df['Isd'].mean():.6f}, std={edc_df['Isd'].std():.6f}\")\n",
    "        print(f\"  Range: [{edc_df['Isd'].min():.6f}, {edc_df['Isd'].max():.6f}]\")\n",
    "        \n",
    "        return edc_df\n",
    "    \n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "# Load EDC data\n",
    "edc_df = load_edc_first_5min(\"09-20-2006/fluctuation-rawdata.zip\")\n",
    "\n",
    "# Save for future use\n",
    "edc_df.to_csv('edc_data.csv', index=False)\n",
    "print(\"\\nSaved to 'edc_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e4ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FULL EDC dataset (this may take a few minutes)...\n",
      "\n",
      "Extracting 09-20-2006/fluctuation-rawdata.zip...\n",
      "Found 2030 EDC files\n",
      "Estimated: ~101,500,000 samples\n",
      "  200/2030 files, 10,000,000 samples so far\n",
      "  400/2030 files, 20,000,000 samples so far\n",
      "  600/2030 files, 30,000,000 samples so far\n",
      "  800/2030 files, 40,000,000 samples so far\n",
      "  1000/2030 files, 50,000,000 samples so far\n",
      "  1200/2030 files, 60,000,000 samples so far\n",
      "  1400/2030 files, 70,000,000 samples so far\n",
      "  1600/2030 files, 80,000,000 samples so far\n",
      "  1800/2030 files, 90,000,000 samples so far\n",
      "  2000/2030 files, 100,000,000 samples so far\n",
      "\n",
      "Concatenating 2030 chunks...\n",
      "Creating DataFrame...\n",
      "\n",
      "Complete EDC Dataset:\n",
      "  Samples: 101,535,470\n",
      "  Duration: 33.85 minutes\n",
      "  Memory: 1549 MB\n",
      "\n",
      "  Isd: mean=0.070324, std=0.048659\n",
      "  Range: [0.031250, 0.124999]\n",
      "\n",
      "Saving to CSV...\n",
      "Saved as 'edc_full_data.csv'\n",
      "\n",
      "File size: ~2905 MB (estimated)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def load_all_edc_data(zip_path):\n",
    "    \"\"\"Load ALL EDC data (18:26-18:59) using offset +3\"\"\"\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "        \n",
    "        temp_path = Path(temp_dir)\n",
    "        all_files = sorted(temp_path.rglob(\"*.dat\"))\n",
    "        real_files = [f for f in all_files if not f.name.startswith('._')]\n",
    "        \n",
    "        # Filter for EDC period (18:26-18:59)\n",
    "        edc_files = []\n",
    "        for f in real_files:\n",
    "            parts = f.stem.split('.')\n",
    "            if len(parts) >= 4:\n",
    "                try:\n",
    "                    hour, minute = int(parts[2]), int(parts[3])\n",
    "                    if hour == 18 and 26 <= minute <= 59:\n",
    "                        edc_files.append(f)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Found {len(edc_files)} EDC files\")\n",
    "        print(f\"Estimated: ~{len(edc_files) * 50000:,} samples\")\n",
    "        \n",
    "        # Load all files\n",
    "        data_chunks = []\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, filepath in enumerate(edc_files):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                raw = f.read()\n",
    "            \n",
    "            marker_pos = raw.find(b\"Isd\\tVsd\")\n",
    "            offset = marker_pos + len(b\"Isd\\tVsd\") + 3  # +3 offset\n",
    "            trim_len = len(raw) - offset\n",
    "            trimmed = raw[offset:offset + (trim_len - (trim_len % 8))]\n",
    "            chunk = np.frombuffer(trimmed, dtype='<f4').reshape(-1, 2)\n",
    "            \n",
    "            data_chunks.append(chunk)\n",
    "            total_samples += len(chunk)\n",
    "            \n",
    "            if (i + 1) % 200 == 0:\n",
    "                print(f\"  {i+1}/{len(edc_files)} files, {total_samples:,} samples so far\")\n",
    "        \n",
    "        print(f\"\\nConcatenating {len(data_chunks)} chunks...\")\n",
    "        combined = np.vstack(data_chunks)\n",
    "        \n",
    "        print(\"Creating DataFrame...\")\n",
    "        edc_full_df = pd.DataFrame({\n",
    "            'time_s': np.arange(len(combined)) * 0.00002,\n",
    "            'Isd': combined[:, 0],\n",
    "            'Vsd': combined[:, 1]\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nComplete EDC Dataset:\")\n",
    "        print(f\"  Samples: {len(edc_full_df):,}\")\n",
    "        print(f\"  Duration: {edc_full_df['time_s'].iloc[-1]/60:.2f} minutes\")\n",
    "        print(f\"  Memory: {edc_full_df.memory_usage(deep=True).sum()/1024**2:.0f} MB\")\n",
    "        print(f\"\\n  Isd: mean={edc_full_df['Isd'].mean():.6f}, std={edc_full_df['Isd'].std():.6f}\")\n",
    "        print(f\"  Range: [{edc_full_df['Isd'].min():.6f}, {edc_full_df['Isd'].max():.6f}]\")\n",
    "        \n",
    "        return edc_full_df\n",
    "    \n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "# Load complete EDC dataset\n",
    "print(\"Loading FULL EDC dataset (this may take a few minutes)...\\n\")\n",
    "edc_full_df = load_all_edc_data(\"09-20-2006/fluctuation-rawdata.zip\")\n",
    "\n",
    "# Save as CSV\n",
    "print(\"\\nSaving to CSV...\")\n",
    "edc_full_df.to_csv('edc_full_data.csv', index=False)\n",
    "print(\"Saved as 'edc_full_data.csv'\")\n",
    "\n",
    "print(f\"\\nFile size: ~{len(edc_full_df) * 30 / 1024**2:.0f} MB (estimated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30a225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
